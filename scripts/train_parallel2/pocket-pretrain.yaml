# This config describes params for pocket pretrain task
enable_modelarts: True
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Local params
run_distribute: False
enable_profiling: False
device_target: "Ascend"
checkpoint_path: ""
checkpoint_file_path: ""
# ==============================================================================
# Training options
batch_size: 128
epochs: 200
# dataset params
lmdb_dataset_path: ""
atoms_vocab_path: ""
is_train: True
remove_hydrogen: False
max_atoms: 512
prob_mask: 0.15
prob_unmask: 0.15
prob_random_token: 0.15
coords_noise_type: "uniform"
coords_noise_coef: 3.0
# optimizer params
optimizer: "adam"
beta1: 0.9 
beta2: 0.99
eps: 1.0e-6
weight_decay: 1.0e-4
# learning rate + warmup params
peak_lr: 1.0e-4
warmup_steps: 10000
max_steps: 1000000
# model params
dictionary_path: ""
encoder_layers: 15
encoder_emb_dim: 512
encoder_ff_emb_dim: 2048
encoder_attention_heads: 64
gaus_kernel_channel: 128
emb_dropout: 0.9
dropout: 0.9
attention_dropout: 0.9
clf_head_dropout: 0.9
max_seq_len: 256
# loss params
token_loss_coef: 1.0
coords_loss_coef: 1.0
distance_loss_coef: 1.0